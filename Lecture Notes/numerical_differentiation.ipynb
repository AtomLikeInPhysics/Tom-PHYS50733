{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f7446d8-460b-4375-ae10-ded0d12f5a72",
   "metadata": {},
   "source": [
    "# Numerical Differentiation\n",
    "\n",
    "Let's start with an analytic function we can solve exactly as we did with integration to see some limit.\n",
    "\n",
    "We'll use a relatively trivial function, $f(x) = 2 x^2$. We can immediately write $f'(x) = 4 x$.\n",
    "\n",
    "Let's calculate a derivative at $x = 2$ and $x = 100$ using the forward or backward difference method. Section 5.10.2 suggests we can use a step size on the order of $h \\approx 10^{-8}$. Try at least three different step sizes of varying orders of magnitude. How does each compare to the known correct value?\n",
    "\n",
    "Repeat the exercise using the central difference method. You should find it is noticably more accurate. If it isn't obvious, try a larger (i.e. purposefully less precise) step size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d5be418-2a67-4e64-9ca6-122e276cc581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The forward difference method for x=2: 8.000711204658728\n",
      "The backwards difference method for x=2: 8.000711204658728\n",
      "The central difference method for x=2: 8.000711204658728\n",
      "The forward difference method for x=100: 396.5396899729967\n",
      "The forward difference method for x=100: 396.5396899729967\n",
      "The forward difference method for x=100: 400.1776687800884\n"
     ]
    }
   ],
   "source": [
    "def function(x):\n",
    "    return(2*x**2)\n",
    "\n",
    "def forDiff(x, h = 10**-8):\n",
    "    return((function(x + h) - function(x)) / h)\n",
    "\n",
    "def backDiff(x,h = 10**-8):\n",
    "    return((function(x) - function(x - h)) / h)\n",
    "\n",
    "def centDiff(x,h = 10**-8):\n",
    "    return((function(x + h/2) - function(x - h/2)) / h)\n",
    "\n",
    "print(\"The forward difference method for x=2:\",forDiff(2 , h = 10**-12))\n",
    "print(\"The backwards difference method for x=2:\",backDiff(2 , h = 10**-12))\n",
    "print(\"The central difference method for x=2:\",centDiff(2 , h = 10**-12))\n",
    "print(\"The forward difference method for x=100:\",forDiff(100, h = 10**-12))\n",
    "print(\"The forward difference method for x=100:\",backDiff(100, h = 10**-12))\n",
    "print(\"The forward difference method for x=100:\",centDiff(100, h = 10**-12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da045a4f-7863-4a40-a4c8-493756d895ef",
   "metadata": {},
   "source": [
    "## Discrete data points\n",
    "\n",
    "As we saw with integrals, real data doesn't come as a smooth function we can evaluate anywhere. To save you the headache of reading in a file, we'll create our own fake data. The code below creates an array x, sampled at an interval of 0.1, and an array y, the output of our previous $f(x)$. \n",
    "\n",
    "Again, evaluate the derivative at $x = 2$ and $x = 100$. \n",
    "\n",
    "Hint: find the documentation on the numpy function argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9d1d5079-ea6c-405f-a699-8b5b7ecd6aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.999999999999998\n",
      "400.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.arange(0, 110, 0.1)\n",
    "y = np.array([2 * i**2 for i in x])\n",
    "\n",
    "def centDiff(xval,y,h=0.1):\n",
    "    a = np.argmin(np.abs(x - xval))\n",
    "    b = np.argmin(np.abs(x - xval - h))\n",
    "    c = np.argmin(np.abs(x - xval + h))\n",
    "    return((y[b] - y[c]) / (2*h))\n",
    "\n",
    "print(centDiff(2,y))\n",
    "print(centDiff(100,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b852eb-8d7c-42f2-96f9-9669bd36e9fe",
   "metadata": {},
   "source": [
    "Create a new discrete dataset with x sampled at an interval of 0.001 and repeat the exercise. The results should not be surprising, but the exercise is worth doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d486224-7279-4c56-bf62-66823cf92467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.999999999999119\n",
      "400.0000000014552\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(0, 110, 0.001)\n",
    "y = np.array([2 * i**2 for i in x])\n",
    "\n",
    "def centDiff(xval,y,h=0.001):\n",
    "    a = np.argmin(np.abs(x - xval))\n",
    "    b = np.argmin(np.abs(x - xval - h))\n",
    "    c = np.argmin(np.abs(x - xval + h))\n",
    "    return((y[b] - y[c]) / (2*h))\n",
    "\n",
    "print(centDiff(2,y))\n",
    "print(centDiff(100,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fd6df8-8e04-4043-abba-499e41f5a968",
   "metadata": {},
   "source": [
    "## Noisy discrete data\n",
    "\n",
    "Section 5.10.7 briefly discusses derivatives of noisy data. Unfortunately there isn't a lot of discussion; one could imagine plenty of scenarios where you might want to calculate a derivative from noisy data, e.g. monitoring trends in a data stream from an instrument, or sometimes the derivative of a measurement is interesting in its own right.\n",
    "\n",
    "Since the derivative is simply $\\frac{dy}{dx}$, one can calculate a derivative over time by plotting $\\frac{f(x_i) - f(x_{i-1})}{x_i - x_{i-1}}$. Use this method to plot the derivative of the discrete dataset you created above. Not surprisingly you should find a very straight line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab01030d-ac51-4bbb-9fb7-68ce2146e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc063b18-f31d-406a-bdfd-8ddb4aacda58",
   "metadata": {},
   "source": [
    "Now let's create a noisy version of our function. Calculate the running $\\frac{f(x_i) - f(x_{i-1})}{x_i - x_{i-1}}$ derivative for this noisy data and plot the result (plot $x$ vs $f'(x)$).\n",
    "\n",
    "Not surprisingly, it's a bit terrible. The step size is small compared to the error we applied, so we're dividing \"noise\" by a small decimal, making it noisier.\n",
    "\n",
    "There are a few solutions given in Section 5.10.7. A simple solution is to sample over a wider range of data points, so rather than using the smallest possible $dx$, choose a $dx$ more appropriate for the data. Note $dx$ will be a number, not a number of points, but you will need to determine a translation between your more appropriately sized $dx$ and your data.\n",
    "\n",
    "In the previous plots, we have not carefully defined the relationship between $x$, $f(x)$ and $f'(x)$. Now that you are using non-adjacent points to calculate a derivative at $x$, you should put some thought into what computed derivative matches which $x$. There are more correct and less correct answers here, but at a minimum you will have to change the size of $x$ because your derivative array/list will have fewer points than $x$.\n",
    "\n",
    "If you're inclined, write a loop that tests different values. It's not a lot of work and the series of plots is quite satisfying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d353e-de37-4e65-9f47-a07c61561abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(0, 110, 0.01)\n",
    "y = np.array([2 * i**2 for i in x])\n",
    "noise = np.random.randn(len(x)) * 1.5\n",
    "noisy = y + noise\n",
    "\n",
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535dea25-7f7a-47cf-b718-660e5ff28ff5",
   "metadata": {},
   "source": [
    "### If you have extra time\n",
    "\n",
    "The other method suggested in the text for finding a derivative is fitting a function to the data and using that function with a forward/backward or central difference method to find a derivative.\n",
    "\n",
    "In this case, we've cheated a bit and already know the form for the function we want to fit. But also it's fairly obvious that the data follow a polynomial form. You can leverage the numpy functionality polyfit to solve the problem, and combine it with poly1d to quickly obtain a callable function you can use for your derivative.\n",
    "\n",
    "Evaluate the derivative at a few points. How does the accuracy compare to other methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa2c7c-2706-4e86-92c6-b9817cc370ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
